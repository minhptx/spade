{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37676</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>9</li>\n",
       "  <li><b>Cores: </b>72</li>\n",
       "  <li><b>Memory: </b>810.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37676' processes=9 threads=72, memory=810.00 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:37676\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n",
      "Index(['data', 'count'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "for csv_file in glob.glob(\"../../../data/train/viznet/ngram/*.csv\"):\n",
    "    file_path = Path(csv_file)\n",
    "    \n",
    "    df = dd.read_csv(file_path, keep_default_na=False, dtype=str)\n",
    "    df = df.rename(columns={\"Unnamed: 0\": \"data\", \"2_gram\": \"count\", \"3_gram\": \"count\", \"4_gram\": \"count\"})\n",
    "    print(df.columns)\n",
    "    output_path = file_path.parent / file_path.stem\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_json(str(output_path), compute=True, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ngram_indexed = True\n",
    "tok_ngram_indexed = True\n",
    "n_indices_indexed = True\n",
    "indices_indexed = True\n",
    "\n",
    "if not es.indices.exists(index=\"char_ngram\"):\n",
    "    es.indices.create(\n",
    "        index=\"char_ngram\",\n",
    "        body={\n",
    "            \"settings\": {\"number_of_shards\": 5},\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\"data\": {\"type\": \"keyword\"}, \"count\": {\"type\": \"long\"},}\n",
    "            },\n",
    "        },\n",
    "        ignore=400,\n",
    "    )\n",
    "    char_ngram_indexed = False\n",
    "\n",
    "if not es.indices.exists(index=\"tok_ngram\"):\n",
    "    es.indices.create(\n",
    "        index=\"tok_ngram\",\n",
    "        body={\n",
    "            \"settings\": {\"number_of_shards\": 5},\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\"data\": {\"type\": \"keyword\"}, \"count\": {\"type\": \"long\"},}\n",
    "            },\n",
    "        },\n",
    "        ignore=400,\n",
    "    )\n",
    "    tok_ngram_indexed = False\n",
    "\n",
    "if not es.indices.exists(index=\"reversed_indices\"):\n",
    "    es.indices.create(\n",
    "        index=\"reversed_indices\",\n",
    "        body={\n",
    "            \"settings\": {\"number_of_shards\": 5},\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\"data\": {\"type\": \"keyword\"}, \"idx\": {\"type\": \"long\"},}\n",
    "            },\n",
    "        },\n",
    "        ignore=400,\n",
    "    )\n",
    "    indices_indexed = False\n",
    "\n",
    "if not es.indices.exists(index=\"n_reversed_indices\"):\n",
    "    es.indices.create(\n",
    "        index=\"n_reversed_indices\",\n",
    "        body={\n",
    "            \"settings\": {\"number_of_shards\": 5},\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\"data\": {\"type\": \"keyword\"}, \"idx\": {\"type\": \"long\"},}\n",
    "            },\n",
    "        },\n",
    "        ignore=400,\n",
    "    )\n",
    "    n_indices_indexed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "\n",
    "import rapidjson as json\n",
    "\n",
    "for sub_path in Path(\"../../../data/train/viznet/ngram\").iterdir():\n",
    "    if \"2_gram_count\" not in sub_path.name:\n",
    "        continue\n",
    "    if sub_path.is_dir() and \"token\" not in sub_path.name and not char_ngram_indexed:\n",
    "        for file_path in sub_path.iterdir():\n",
    "            print(file_path)\n",
    "            if file_path.suffix == \".part\":\n",
    "                with gzip.GzipFile(file_path, \"r\") as fin:\n",
    "                    data = [json.loads(l) for l in fin.readlines()]\n",
    "                    print(data[:1])\n",
    "                    try:\n",
    "                        deque(\n",
    "                            helpers.parallel_bulk(es, data, index=\"char_ngram\"),\n",
    "                            maxlen=0,\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(i, e)\n",
    "                        continue\n",
    "    elif sub_path.is_dir() and not tok_ngram_indexed:\n",
    "        for file_path in sub_path.iterdir():\n",
    "            print(file_path)\n",
    "            if file_path.suffix == \".part\":\n",
    "                with gzip.GzipFile(file_path, \"r\") as fin:\n",
    "                    data = [json.loads(l) for l in fin.readlines()]\n",
    "                    try:\n",
    "                        deque(\n",
    "                            helpers.parallel_bulk(es, data, index=\"tok_ngram\"), maxlen=0\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "\n",
    "# for sub_path in Path(\"../../../data/train/viznet\").iterdir():\n",
    "#     print(sub_path)\n",
    "#     if sub_path.suffix == \".jsonl\":\n",
    "#         if \"pattern_n_cooc\" in str(sub_path) and not n_indices_indexed:\n",
    "#             print(\"Indexing\")\n",
    "#             with open(sub_path, \"r\") as fin:\n",
    "#                 data = [json.loads(l) for l in fin.readlines()]\n",
    "#                 for i in range(0, len(data), 50):\n",
    "#                     try:\n",
    "#                         deque(\n",
    "#                             helpers.parallel_bulk(\n",
    "#                                 es, data[i : i + 50], index=\"n_reversed_indices\"\n",
    "#                             ),\n",
    "#                             maxlen=0,\n",
    "#                         )\n",
    "#                     except Exception as e:\n",
    "#                         print(i, e)\n",
    "#                         continue\n",
    "#         elif not indices_indexed:\n",
    "#             with open(sub_path, \"r\") as fin:\n",
    "#                 data = [json.loads(l) for l in fin.readlines()]\n",
    "#                 for i in range(0, len(data), 1000):\n",
    "#                     try:\n",
    "#                         deque(\n",
    "#                             helpers.parallel_bulk(\n",
    "#                                 es, data[i : i + 50], index=\"reversed_indices\"\n",
    "#                             ),\n",
    "#                             maxlen=0,\n",
    "#                         )\n",
    "#                     except Exception as e:\n",
    "#                         print(i, e)\n",
    "#                         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('torch': conda)",
   "language": "python",
   "name": "python37764bittorchconda619657fd9e3249e097c69e9d63018998"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
