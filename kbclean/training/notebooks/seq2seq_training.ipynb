{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "if r\"../../../kb-data-cleaning/kbclean\" not in sys.path:\n",
    "    sys.path.append(r\"../../../kb-data-cleaning/kbclean\")\n",
    "\n",
    "method = \"vseq2seq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 2000,\n",
       " 'enc_emb_dim': 50,\n",
       " 'dec_emb_dim': 50,\n",
       " 'enc_hid_dim': 50,\n",
       " 'dec_hid_dim': 50,\n",
       " 'latent_dim': 10,\n",
       " 'dropout_p': 0.5,\n",
       " 'lr': 0.0005,\n",
       " 'use_sm': False,\n",
       " 'amp_level': 'O1',\n",
       " 'teacher_forcing_ratio': 0.5,\n",
       " 'max_length': 100}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "hparams = yaml.load(open(f\"../../config/{method}.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "\n",
    "hparams = Namespace(**hparams)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/test/ed2_cols/Beers_abv.csv\", dtype=str, keep_default_na=False)\n",
    "\n",
    "data = df.iloc[:, 0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import regex as re\n",
    "from torchnlp.encoders import LabelEncoder\n",
    "from torchnlp.encoders.text import CharacterEncoder\n",
    "\n",
    "printable = set(string.printable)\n",
    "\n",
    "\n",
    "def to_regex(s):\n",
    "    s = \"\".join(filter(lambda x: x in printable, s))\n",
    "    s = re.sub(\"[A-Z]\", \"A\", s)\n",
    "    s = re.sub(\"[a-z]\", \"a\", s)\n",
    "    s = re.sub(\"[0-9]\", \"0\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "# data = [to_regex(val) for val in data]\n",
    "\n",
    "char_encoder = CharacterEncoder(data, append_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.vocab_size = char_encoder.vocab_size\n",
    "hparams.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, random_split\n",
    "from torchnlp.encoders.text import stack_and_pad_tensors\n",
    "from torchnlp.samplers import BucketBatchSampler\n",
    "\n",
    "data_with_labels = [\n",
    "    example[:100] for example in data if example\n",
    "]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, lengths = char_encoder.batch_encode(batch)\n",
    "    return inputs, lengths, batch\n",
    "\n",
    "train_length = int(len(data_with_labels) * 0.7)\n",
    "train_dataset, val_dataset = random_split(\n",
    "    list(data_with_labels), [train_length, len(data_with_labels) - train_length],\n",
    ")\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=hparams.batch_size, collate_fn=collate_fn, num_workers=16,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=hparams.batch_size, collate_fn=collate_fn, num_workers=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class PredictionCallback(Callback):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        sampled_data = random.choices(self.data, k=10)\n",
    "        inp, lengths, examples = collate_fn(sampled_data)\n",
    "        dec_outputs, _ = pl_module.forward(inp.cuda(), lengths.cuda())\n",
    "        best_outputs = torch.argmax(dec_outputs, dim=2)\n",
    "        print(list(zip(char_encoder.batch_decode(best_outputs, lengths), examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "   | Name                           | Type      | Params\n",
      "---------------------------------------------------------\n",
      "0  | attn                           | Attention | 7 K   \n",
      "1  | attn.attn                      | Linear    | 7 K   \n",
      "2  | attn.v                         | Linear    | 50    \n",
      "3  | encoder                        | Encoder   | 36 K  \n",
      "4  | encoder.embedding              | Embedding | 850   \n",
      "5  | encoder.rnn                    | GRU       | 30 K  \n",
      "6  | encoder.fc                     | Linear    | 5 K   \n",
      "7  | encoder.dropout                | Dropout   | 0     \n",
      "8  | decoder                        | Decoder   | 42 K  \n",
      "9  | decoder.embedding              | Embedding | 850   \n",
      "10 | decoder.rnn                    | GRU       | 30 K  \n",
      "11 | decoder.fc_out                 | Linear    | 3 K   \n",
      "12 | decoder.dropout                | Dropout   | 0     \n",
      "13 | hidden2latent                  | Lambda    | 1 K   \n",
      "14 | hidden2latent.hidden_to_mean   | Linear    | 510   \n",
      "15 | hidden2latent.hidden_to_logvar | Linear    | 510   \n",
      "16 | latent2hidden                  | Linear    | 550   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0189355c5e3f4bf69d8b204113d1dff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940b6212cb4b4a1bb9eccb4e24a89386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/minhpham/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00.</s>7', '0.05'), ('040<unk></s>2', '0.049'), ('0985</s>', '0.09'), ('048<copy><unk>2', '0.068'), ('00.4%9', '0.07%'), ('04<pad>145', '0.053'), ('09.419', '0.052'), ('0<copy>84</s>', '0.08'), ('04<unk>91%9</s>44%454497%458<unk>', '0.052000000000000005%'), ('011419', '0.054')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import MLFlowLogger, TensorBoardLogger\n",
    "\n",
    "from models.auto_encoder import Seq2Seq, VSeq2Seq\n",
    "char_encoder.padding_index\n",
    "\n",
    "if method == \"seq2seq\":\n",
    "    seq2seq = Seq2Seq(hparams, char_encoder.padding_index)\n",
    "else:\n",
    "    seq2seq = VSeq2Seq(hparams, char_encoder.padding_index)\n",
    "\n",
    "trainer = Trainer(\n",
    "    gpus=[0, 1, 2, 3],\n",
    "    amp_level=hparams.amp_level,\n",
    "    distributed_backend=\"dp\",\n",
    "    callbacks=[PredictionCallback(data_with_labels)],\n",
    "    logger=TensorBoardLogger(\"../../tt_logs\", \"vseq2seq\"),\n",
    "    max_epochs=1\n",
    ")\n",
    "trainer.fit(\n",
    "    seq2seq, train_dataloader=train_dataloader, val_dataloaders=[val_dataloader]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn2(batch):\n",
    "    data, lengths = char_encoder.batch_encode(batch)\n",
    "    return data.cuda(), lengths.cuda()\n",
    "\n",
    "full_dataloader = DataLoader(\n",
    "    [example[:100] for example in data], batch_size=hparams.batch_size, collate_fn=collate_fn2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_batches = []\n",
    "\n",
    "for data, lengths in full_dataloader:\n",
    "    encoded_batches.append(seq2seq.encode(data, lengths).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (2000, 20))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_batches), encoded_batches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "encoded_data = np.concatenate(encoded_batches, axis=0)\n",
    "np.save(\"../../data/numpy/encoded.npy\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
