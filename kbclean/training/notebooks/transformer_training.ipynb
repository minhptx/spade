{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Detection - Training LSTM model (char + word embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment (Pytorch + Pandas + Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "\n",
    "if r\"../../../kb-data-cleaning/kbclean\" not in sys.path:\n",
    "    sys.path.append(r\"../../../kb-data-cleaning/kbclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import load_hparams\n",
    "\n",
    "hparams = load_hparams(\"../../config/hparams.yaml\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using TorchText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def preprocess(str1):\n",
    "    str1 = \"\".join(str1)\n",
    "    str1 = re.sub(\"[A-Z]\", \"A\", str1)\n",
    "    str1 = re.sub(\"[a-z]\", \"a\", str1)\n",
    "    str1 = re.sub(\"[0-9]\", \"0\", str1)\n",
    "\n",
    "    return list(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchtext.data import Field, LabelField, NestedField, TabularDataset\n",
    "\n",
    "char_field = Field(\n",
    "    tokenize=list,\n",
    "    pad_token=\"<wpad>\",\n",
    "    batch_first=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    ")\n",
    "\n",
    "label = LabelField()\n",
    "\n",
    "dataset = TabularDataset(\n",
    "    path=\"../../data/train/train_500000c.csv\",\n",
    "    format=\"csv\",\n",
    "    fields={\n",
    "        \"str1\": [(\"src_char\", char_field)],\n",
    "        \"str2\": [(\"trg_char\", char_field)],\n",
    "        \"sim\": [(\"lbl\", label)],\n",
    "    },\n",
    ")\n",
    "\n",
    "test_dataset = TabularDataset(\n",
    "    path=\"../../data/test/wiki/labeled_output.csv\",\n",
    "    format=\"csv\",\n",
    "    fields={\n",
    "        \"str1\": [(\"src_char\", char_field)],\n",
    "        \"str2\": [(\"trg_char\", char_field)],\n",
    "        \"sim\": [(\"lbl\", label)]\n",
    "    },\n",
    "    csv_reader_params={\n",
    "        \"quotechar\":\"'\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building language vocabulary from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torchtext import vocab\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "char_field.build_vocab(dataset.src_char, dataset.trg_char)\n",
    "\n",
    "label.build_vocab(dataset.lbl)\n",
    "label.vocab.stoi = {\"True\": 0, \"False\": 1}\n",
    "\n",
    "hparams.char_vocab_size = len(char_field.vocab)\n",
    "\n",
    "hparams.char_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "train_iterator = BucketIterator(dataset, device=device, batch_size=hparams.batch_size)\n",
    "test_iterator = BucketIterator(test_dataset, device=device, batch_size=hparams.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing callback function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def idx2word(index_sequences, field):\n",
    "    return \" \".join(\n",
    "        [field.vocab.itos[idx] if idx != 1 else \"\" for idx in index_sequences]\n",
    "    )\n",
    "\n",
    "\n",
    "def show_samples(trainer):\n",
    "    i = 0\n",
    "    for batch in train_iterator:\n",
    "        x, y = batch\n",
    "#         y_hat = trainer(*x)\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            print(\n",
    "                f\"Example {i}: {idx2word(x[0][0][i], word_field)} ---\"\n",
    "                f\" {idx2word(x[1][0][i], word_field)} ==>  --- {y[i].item()}\"\n",
    "            )\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from ml.nets import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    char_vocab_size=hparams.char_vocab_size,\n",
    "    embedding_size=hparams.char_embedding_size,\n",
    "    hidden_size=hparams.hidden_size,\n",
    "    head_size=hparams.head_size,\n",
    "    num_layers=hparams.num_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9685ed6f0c74d749ada9619de4dd3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=22.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=22.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=22.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=22.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "trainer = Trainer(gpus=1, amp_level='O1', benchmark=False, default_save_path=\"../../checkpoints\", )\n",
    "trainer.fit(transformer, train_dataloader=train_iterator, val_dataloaders=[test_iterator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
