batch_size: 32
vocab_size: 50000
max_length: 100
hidden_size: 64
num_hidden_layers: 4
intermediate_size: 128
hidden_dropout_prob: 0.5
num_attention_heads: 8
lr: 0.0005